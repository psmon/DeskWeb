#!/usr/bin/env python3
"""
HWP File Analyzer
HWP 5.0 íŒŒì¼ êµ¬ì¡°ë¥¼ ë¶„ì„í•˜ëŠ” Python ë„êµ¬
"""

import struct
import sys
import os
try:
    import olefile
except ImportError:
    print("olefile ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤:")
    print("pip install olefile")
    sys.exit(1)

try:
    import zlib
except ImportError:
    print("zlib ëª¨ë“ˆì´ í•„ìš”í•©ë‹ˆë‹¤ (Python ê¸°ë³¸ ì œê³µ)")
    sys.exit(1)


class HWPAnalyzer:
    """HWP íŒŒì¼ ë¶„ì„ í´ë˜ìŠ¤"""

    # íƒœê·¸ ID ë§µí•‘
    TAG_NAMES = {
        0x10: 'DOCUMENT_PROPERTIES',
        0x11: 'ID_MAPPINGS',
        0x12: 'BIN_DATA',
        0x13: 'FACE_NAME',
        0x14: 'BORDER_FILL',
        0x15: 'CHAR_SHAPE',
        0x16: 'TAB_DEF',
        0x17: 'NUMBERING',
        0x18: 'BULLET',
        0x19: 'PARA_SHAPE',
        0x1A: 'STYLE',
        0x50: 'PARA_HEADER',
        0x51: 'PARA_TEXT',
        0x52: 'PARA_CHAR_SHAPE',
        0x53: 'PARA_LINE_SEG',
        0x54: 'PARA_RANGE_TAG',
        0x55: 'CTRL_HEADER',
        0x56: 'LIST_HEADER',
        0x57: 'PAGE_DEF',
        0x58: 'FOOTNOTE_SHAPE',
        0x59: 'PAGE_BORDER_FILL',
        0x5A: 'SHAPE_COMPONENT',
        0x5B: 'TABLE'
    }

    def __init__(self, filepath):
        """ì´ˆê¸°í™”"""
        self.filepath = filepath
        self.ole = None
        self.file_header = None

    def open(self):
        """HWP íŒŒì¼ ì—´ê¸°"""
        if not os.path.exists(self.filepath):
            raise FileNotFoundError(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.filepath}")

        self.ole = olefile.OleFileIO(self.filepath)
        return self

    def close(self):
        """HWP íŒŒì¼ ë‹«ê¸°"""
        if self.ole:
            self.ole.close()

    def __enter__(self):
        """ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ì ì§„ì…"""
        return self.open()

    def __exit__(self, exc_type, exc_val, exc_tb):
        """ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ì ì¢…ë£Œ"""
        self.close()

    def list_streams(self):
        """ëª¨ë“  ìŠ¤íŠ¸ë¦¼ ëª©ë¡ ë°˜í™˜"""
        return self.ole.listdir()

    def read_stream(self, stream_name):
        """íŠ¹ì • ìŠ¤íŠ¸ë¦¼ ì½ê¸°"""
        try:
            if isinstance(stream_name, list):
                return self.ole.openstream(stream_name).read()
            else:
                # ë¬¸ìì—´ì¸ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                parts = stream_name.split('/')
                return self.ole.openstream(parts).read()
        except:
            return None

    def parse_file_header(self):
        """FileHeader íŒŒì‹±"""
        data = self.read_stream('FileHeader')
        if not data or len(data) < 256:
            raise ValueError("FileHeaderê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")

        # Signature (32 bytes)
        signature = data[:32].decode('utf-8', errors='ignore').rstrip('\x00')

        # Version (4 bytes) - Little Endian
        version_raw = struct.unpack('<I', data[32:36])[0]
        version = {
            'raw': version_raw,
            'major': (version_raw >> 24) & 0xFF,
            'minor': (version_raw >> 16) & 0xFF,
            'patch': (version_raw >> 8) & 0xFF,
            'revision': version_raw & 0xFF
        }
        version['string'] = f"{version['major']}.{version['minor']}.{version['patch']}.{version['revision']}"

        # Flags (4 bytes)
        flags_raw = struct.unpack('<I', data[36:40])[0]
        flags = {
            'raw': flags_raw,
            'compressed': bool(flags_raw & 0x01),
            'encrypted': bool(flags_raw & 0x02),
            'distribution': bool(flags_raw & 0x04),
            'script': bool(flags_raw & 0x08),
            'drm': bool(flags_raw & 0x10),
            'xmlTemplate': bool(flags_raw & 0x20),
            'history': bool(flags_raw & 0x40),
            'signature': bool(flags_raw & 0x80),
            'certificate': bool(flags_raw & 0x100)
        }

        # Flags2 (4 bytes)
        flags2_raw = struct.unpack('<I', data[40:44])[0]

        # Encrypt Version (4 bytes)
        encrypt_version = struct.unpack('<I', data[44:48])[0]

        # KOGL License (1 byte)
        kogl_license = struct.unpack('B', data[48:49])[0]

        self.file_header = {
            'signature': signature,
            'version': version,
            'flags': flags,
            'flags2': flags2_raw,
            'encrypt_version': encrypt_version,
            'kogl_license': kogl_license
        }

        return self.file_header

    def parse_records(self, data, is_compressed=False):
        """ë ˆì½”ë“œ êµ¬ì¡° íŒŒì‹±"""
        # ë¨¼ì € ì „ì²´ ìŠ¤íŠ¸ë¦¼ ì••ì¶• í•´ì œ ì‹œë„
        if is_compressed and len(data) > 0:
            try:
                data = zlib.decompress(data, -15)  # raw deflate
                print(f"  [INFO] ì „ì²´ ìŠ¤íŠ¸ë¦¼ ì••ì¶• í•´ì œ ì„±ê³µ: {len(data)} bytes")
            except:
                try:
                    data = zlib.decompress(data)
                    print(f"  [INFO] ì „ì²´ ìŠ¤íŠ¸ë¦¼ ì••ì¶• í•´ì œ ì„±ê³µ (zlib): {len(data)} bytes")
                except:
                    print(f"  [WARNING] ì „ì²´ ìŠ¤íŠ¸ë¦¼ ì••ì¶• í•´ì œ ì‹¤íŒ¨, ì›ë³¸ ì‚¬ìš©")

        records = []
        offset = 0

        while offset < len(data) - 4:
            try:
                # ë ˆì½”ë“œ í—¤ë” (4 bytes, Little Endian)
                header = struct.unpack('<I', data[offset:offset+4])[0]
                offset += 4

                tag_id = header & 0x3FF           # 10 bits
                level = (header >> 10) & 0x3FF    # 10 bits
                size = (header >> 20) & 0xFFF     # 12 bits

                # Sizeê°€ 0xFFFì¸ ê²½ìš° ë‹¤ìŒ 4ë°”ì´íŠ¸ì—ì„œ ì‹¤ì œ í¬ê¸° ì½ê¸°
                if size == 0xFFF:
                    if offset + 4 > len(data):
                        break
                    size = struct.unpack('<I', data[offset:offset+4])[0]
                    offset += 4

                # ë°ì´í„° ë²”ìœ„ í™•ì¸
                if offset + size > len(data):
                    print(f"  [WARNING] ë ˆì½”ë“œ í¬ê¸° ì´ˆê³¼: tagId=0x{tag_id:02x}, offset={offset}, size={size}, data_len={len(data)}")
                    break

                # ë ˆì½”ë“œ ë°ì´í„° ì½ê¸° (ì´ë¯¸ ìŠ¤íŠ¸ë¦¼ ë‹¨ìœ„ë¡œ ì••ì¶• í•´ì œë¨)
                record_data = data[offset:offset+size]
                offset += size

                records.append({
                    'tag_id': tag_id,
                    'tag_name': self.TAG_NAMES.get(tag_id, f'UNKNOWN(0x{tag_id:02x})'),
                    'level': level,
                    'size': size,
                    'data': record_data
                })

            except Exception as e:
                print(f"  [ERROR] ë ˆì½”ë“œ íŒŒì‹± ì˜¤ë¥˜ at offset {offset}: {e}")
                break

        return records

    def parse_para_text(self, data):
        """ë¬¸ë‹¨ í…ìŠ¤íŠ¸ íŒŒì‹± (UTF-16LE)"""
        try:
            text = data.decode('utf-16le', errors='ignore')
            # ì œì–´ ë¬¸ì í•„í„°ë§
            text = ''.join(c for c in text if ord(c) >= 32 or c == '\n' or c == '\t')
            return text
        except:
            return ""

    def analyze_section(self, section_index):
        """ì„¹ì…˜ ë¶„ì„"""
        # BodyText/SectionX ë˜ëŠ” SectionX ì‹œë„
        section_name = f'BodyText/Section{section_index}'
        data = self.read_stream(section_name)

        if not data:
            section_name = f'Section{section_index}'
            data = self.read_stream(section_name)

        if not data:
            return None

        print(f"\n{'='*60}")
        print(f"Section {section_index} ({section_name})")
        print(f"{'='*60}")
        print(f"ì›ë³¸ í¬ê¸°: {len(data)} bytes")
        print(f"ì²« 4ë°”ì´íŠ¸: 0x{data[:4].hex()}")

        # ë ˆì½”ë“œ íŒŒì‹±
        is_compressed = self.file_header['flags']['compressed'] if self.file_header else False
        records = self.parse_records(data, is_compressed)

        print(f"íŒŒì‹±ëœ ë ˆì½”ë“œ ìˆ˜: {len(records)}")

        # ë ˆì½”ë“œ íƒ€ì…ë³„ í†µê³„
        tag_counts = {}
        for record in records:
            tag_name = record['tag_name']
            tag_counts[tag_name] = tag_counts.get(tag_name, 0) + 1

        print(f"\në ˆì½”ë“œ íƒ€ì…ë³„ ë¶„í¬:")
        for tag_name, count in sorted(tag_counts.items()):
            print(f"  {tag_name}: {count}ê°œ")

        # ë¬¸ë‹¨ ì¶”ì¶œ
        paragraphs = []
        for i, record in enumerate(records):
            if record['tag_id'] == 0x50:  # PARA_HEADER
                text = ""
                # ë‹¤ìŒ ë ˆì½”ë“œê°€ PARA_TEXTì¸ì§€ í™•ì¸
                if i + 1 < len(records) and records[i + 1]['tag_id'] == 0x51:
                    text = self.parse_para_text(records[i + 1]['data'])
                paragraphs.append(text)

        print(f"\nì¶”ì¶œëœ ë¬¸ë‹¨ ìˆ˜: {len(paragraphs)}")

        # ë¬¸ë‹¨ ë¯¸ë¦¬ë³´ê¸°
        if paragraphs:
            print(f"\në¬¸ë‹¨ ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 5ê°œ):")
            for i, text in enumerate(paragraphs[:5]):
                preview = text[:50].replace('\n', ' ')
                if len(text) > 50:
                    preview += '...'
                print(f"  P{i}: ({len(text)}ì) \"{preview}\"")

        return {
            'section_index': section_index,
            'section_name': section_name,
            'raw_size': len(data),
            'records': records,
            'paragraphs': paragraphs
        }

    def analyze_docinfo(self):
        """DocInfo ë¶„ì„"""
        data = self.read_stream('DocInfo')
        if not data:
            print("DocInfo ìŠ¤íŠ¸ë¦¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return None

        print(f"\n{'='*60}")
        print(f"DocInfo")
        print(f"{'='*60}")
        print(f"ì›ë³¸ í¬ê¸°: {len(data)} bytes")

        # ë ˆì½”ë“œ íŒŒì‹±
        is_compressed = self.file_header['flags']['compressed'] if self.file_header else False
        records = self.parse_records(data, is_compressed)

        print(f"íŒŒì‹±ëœ ë ˆì½”ë“œ ìˆ˜: {len(records)}")

        # ë ˆì½”ë“œ íƒ€ì…ë³„ í†µê³„
        tag_counts = {}
        for record in records:
            tag_name = record['tag_name']
            tag_counts[tag_name] = tag_counts.get(tag_name, 0) + 1

        print(f"\në ˆì½”ë“œ íƒ€ì…ë³„ ë¶„í¬:")
        for tag_name, count in sorted(tag_counts.items()):
            print(f"  {tag_name}: {count}ê°œ")

        return {
            'raw_size': len(data),
            'records': records
        }

    def analyze_prvtext(self):
        """PrvText ë¶„ì„"""
        data = self.read_stream('PrvText')
        if not data:
            return None

        print(f"\n{'='*60}")
        print(f"PrvText (ë¯¸ë¦¬ë³´ê¸° í…ìŠ¤íŠ¸)")
        print(f"{'='*60}")
        print(f"ì›ë³¸ í¬ê¸°: {len(data)} bytes")

        # UTF-16LE ë””ì½”ë”©
        try:
            text = data.decode('utf-16le', errors='ignore')
            # ì œì–´ ë¬¸ì í•„í„°ë§
            text = ''.join(c for c in text if ord(c) >= 32 or c == '\n' or c == '\t')

            print(f"í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text)} ë¬¸ì")
            print(f"\në¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 200ì):")
            print("-" * 60)
            print(text[:200])
            if len(text) > 200:
                print("...")
            print("-" * 60)

            return text
        except Exception as e:
            print(f"ë””ì½”ë”© ì˜¤ë¥˜: {e}")
            return None

    def print_file_structure(self):
        """íŒŒì¼ êµ¬ì¡° ì¶œë ¥"""
        print(f"\n{'='*60}")
        print(f"HWP íŒŒì¼ êµ¬ì¡°")
        print(f"{'='*60}")

        streams = self.list_streams()

        # ìŠ¤í† ë¦¬ì§€ë³„ë¡œ ê·¸ë£¹í™”
        storages = {}
        for stream in streams:
            if len(stream) == 1:
                # ë£¨íŠ¸ ë ˆë²¨
                storages.setdefault('ROOT', []).append(stream[0])
            else:
                # ìŠ¤í† ë¦¬ì§€ í•˜ìœ„
                storage_name = stream[0]
                storages.setdefault(storage_name, []).append('/'.join(stream[1:]))

        for storage_name, items in sorted(storages.items()):
            print(f"\nğŸ“ {storage_name}:")
            for item in sorted(items):
                print(f"  ğŸ“„ {item}")

    def full_analysis(self):
        """ì „ì²´ ë¶„ì„ ì‹¤í–‰"""
        print(f"HWP íŒŒì¼ ë¶„ì„: {self.filepath}")
        print(f"íŒŒì¼ í¬ê¸°: {os.path.getsize(self.filepath):,} bytes")

        # íŒŒì¼ êµ¬ì¡°
        self.print_file_structure()

        # FileHeader
        print(f"\n{'='*60}")
        print(f"FileHeader")
        print(f"{'='*60}")
        header = self.parse_file_header()
        print(f"ì„œëª…: {header['signature']}")
        print(f"ë²„ì „: {header['version']['string']}")
        print(f"ì••ì¶• ì—¬ë¶€: {header['flags']['compressed']}")
        print(f"ì•”í˜¸í™” ì—¬ë¶€: {header['flags']['encrypted']}")
        print(f"í”Œë˜ê·¸: 0x{header['flags']['raw']:08x}")

        # PrvText
        self.analyze_prvtext()

        # DocInfo
        self.analyze_docinfo()

        # BodyText Sections
        section_count = 0
        for i in range(10):  # ìµœëŒ€ 10ê°œ ì„¹ì…˜ ì‹œë„
            result = self.analyze_section(i)
            if not result:
                break
            section_count += 1

        # ViewText Sections (ì¶”ê°€ë¡œ í™•ì¸)
        print(f"\n{'='*60}")
        print(f"ViewText Sections (ì°¸ê³ ìš©)")
        print(f"{'='*60}")
        for i in range(10):
            viewtext_name = f'ViewText/Section{i}'
            data = self.read_stream(viewtext_name)
            if data:
                print(f"\n{viewtext_name}: {len(data)} bytes")
                # ViewTextëŠ” ì¼ë°˜ì ìœ¼ë¡œ ì••ì¶•ë˜ì§€ ì•ŠìŒ
                is_compressed = self.file_header['flags']['compressed'] if self.file_header else False
                records = self.parse_records(data, is_compressed)
                print(f"  ë ˆì½”ë“œ ìˆ˜: {len(records)}")
            else:
                break

        print(f"\n{'='*60}")
        print(f"ë¶„ì„ ì™„ë£Œ: ì´ {section_count}ê°œ BodyText ì„¹ì…˜")
        print(f"{'='*60}")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    if len(sys.argv) < 2:
        print("ì‚¬ìš©ë²•: python hwp_analyzer.py <hwp_file_path>")
        print("ì˜ˆì œ: python hwp_analyzer.py test.hwp")
        sys.exit(1)

    hwp_file = sys.argv[1]

    try:
        with HWPAnalyzer(hwp_file) as analyzer:
            analyzer.full_analysis()
    except Exception as e:
        print(f"\nì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main()
